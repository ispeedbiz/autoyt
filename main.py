#!/usr/bin/env python3
# main.py â€” BackToZero fully-autonomous pipeline (scheduled publish)

import os, sys, time, subprocess, traceback, requests, io, textwrap, logging, pickle
from datetime import datetime
from pathlib import Path
import gspread
from openai import OpenAI
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from PIL import Image, ImageDraw, ImageFont
from utils import load_env, get_video_folder, save_text_to_file, log_to_file, sanitize_folder_name

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ config â”€â”€
BASE_DIR            = Path(__file__).parent
VIDEOS_DIR          = BASE_DIR / "videos"
SERVICE_ACCOUNT_FILE = "service_account.json"
SHEET_NAME          = "Back to Zero â€“ Input Sheet"
WORKSHEET_INDEX     = 0
CLIENT_SECRETS_FILE = BASE_DIR / "client_secret.json"
SUPPORTED_LANG      = {"Hindi"}
HINDI_VOICE_ID      = os.getenv("HINDI_VOICE_ID", "EXAVITQu4vr4xnSDxMaL")
FFMPEG_CMD          = "ffmpeg"
MAX_TTS_CHARS       = 5000  # ElevenLabs limit

def sheet_client():
    SCOPES = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ]
    creds = Credentials.from_service_account_file(
        SERVICE_ACCOUNT_FILE,
        scopes=SCOPES
    )
    return gspread.authorize(creds)

def sheet_ws():
    return sheet_client().open(SHEET_NAME).get_worksheet(WORKSHEET_INDEX)

def parse_publish_datetime(s):
    # Accepts both "YYYY-MM-DD" and "YYYY-MM-DD HH:MM"
    try:
        if len(s.strip()) == 10:
            s += " 00:00"
        return datetime.strptime(s, "%Y-%m-%d %H:%M")
    except:
        return None

def list_pending(ws):
    now = datetime.now()
    all_rows = ws.get_all_values()
    pending = []
    for idx, row in enumerate(all_rows[1:], start=2):
        status = (row[5] if len(row) > 5 else "").strip().lower()
        pub_dt = parse_publish_datetime(row[4] if len(row) > 4 else "")
        if status in ("", "ğŸ•“ waiting") and pub_dt and pub_dt <= now:
            pending.append((idx, row))
    return pending

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ logging â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout),
              logging.FileHandler(BASE_DIR / "automation.log")]
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Sheet & scheduling â”€
def parse_publish_datetime(s: str):
    s = s.strip()
    if not s:
        return None
    # allow "YYYY-MM-DD HH:MM" or "YYYY-MM-DD"
    if len(s) == 10:
        s += " 00:00"
    try:
        return datetime.strptime(s, "%Y-%m-%d %H:%M")
    except:
        return None

def list_pending(ws):
    all_rows = ws.get_all_values()
    pending = []
    now = datetime.now()
    for idx, row in enumerate(all_rows[1:], start=2):
        status = (row[5] if len(row) > 5 else "").strip().lower()
        pub_dt = parse_publish_datetime(row[4] if len(row) > 4 else "")
        if status in ("", "ğŸ•“ waiting") and pub_dt and pub_dt <= now:
            pending.append((idx, row))
    return pending

def batch_update(ws, row, status, link="", err="", proc_time=""):
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    ws.batch_update([{
        "range": f"F{row}:J{row}",
        "values": [[status, link, ts, err, proc_time]]
    }])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Data parsing â”€
SUPPORTED_LANGUAGES = {"Hindi"}
def row_to_data(row):
    """Extract and validate all needed fields from a sheet row."""
    def g(i, default=""):
        return row[i].strip() if len(row) > i and row[i].strip() else default

    data = {
        "topic":      g(0),
        "lang":       g(1).capitalize(),
        "title":      g(2),
        "notes":      g(3),
        "pub_date":   g(4),
        "thumb_src":  g(16, "AUTO"),
        "thumb_txt":  g(10, g(2, g(0))),
        "tone":       g(11, "Informative"),
        "highlights": g(12, f"Top insights from â€œ{g(0)}â€"),
        "audience":   g(13, "General viewers"),
        "cta":        g(14, "Subscribe"),
        "duration":   g(15, "Medium (3â€“5 min)"),
        "attrib":     g(17, "")
    }
    if not data["topic"]:
        raise ValueError("Missing Book/Topic")
    if data["lang"] not in SUPPORTED_LANGUAGES:
        raise ValueError(f"Unsupported language: {data['lang']}")
    if not data["title"]:
        data["title"] = data["topic"]
    return data

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Prompt builder â”€

def build_prompt(d):
    """
    Enhanced prompt for top-class, engaging YouTube narration in Hindi-English.
    """
    return textwrap.dedent(f"""
    à¤¤à¥à¤® 'Syllabus with Rohit' à¤œà¥ˆà¤¸à¥€ engaging à¤”à¤° impactful narration à¤¦à¥‡à¤¨à¥‡ à¤µà¤¾à¤²à¥‡ narrator à¤¹à¥‹ â€”
    à¤²à¥‡à¤•à¤¿à¤¨ à¤¶à¥ˆà¤²à¥€ à¤¤à¥à¤®à¥à¤¹à¤¾à¤°à¥€ original à¤¹à¥‹à¤¨à¥€ à¤šà¤¾à¤¹à¤¿à¤: {d['tone']} à¤”à¤° energetic.

    ğŸ”¹ Primary language: à¤¹à¤¿à¤‚à¤¦à¥€ (à¤ªà¤° English proper nouns à¤”à¤° tech terms à¤œà¥ˆà¤¸à¥‡ AI, Finance, Deep Work, Mindset use à¤•à¤°à¥‹)  
    ğŸ”¹ à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤•à¥€ length: {d['duration']} (script â‰¤ 90 seconds)  
    ğŸ”¹ Target audience: {d['audience']}  
    ğŸ”¹ Topic: â€œ{d['topic']}â€

    â€”â€” INTERNAL SCRIPT STRUCTURE (NEVER mention these labels in narration) â€”â€”
    â‘  Hook: Bold question à¤¯à¤¾ striking statement à¤¸à¥‡ à¤¶à¥à¤°à¥‚ à¤•à¤°à¥‹.  
    â‘¡ Context: 1-2 lines à¤®à¥‡à¤‚ à¤¬à¤¤à¤¾à¤“ à¤•à¤¿ à¤¯à¤¹ topic à¤†à¤œ à¤•à¥à¤¯à¥‹à¤‚ à¤œà¤°à¥‚à¤°à¥€ à¤¹à¥ˆ.  
    â‘¢ Takeaways: 3 strong insights (à¤¹à¤° insight â‰¤ 20 words), à¤‡à¤¨ highlights à¤•à¥‹ naturally include à¤•à¤°à¥‹: {d['highlights']}  
    â‘£ Story/Analogy: à¤à¤• short, relatable example à¤¯à¤¾ Indian story (â‰¤ 30 words).  
    â‘¤ Reflective Question: à¤à¤• insightful à¤¸à¤µà¤¾à¤² viewer à¤¸à¥‡ direct à¤ªà¥‚à¤›à¥‹.  
    â‘¥ CTA: Warm, natural Hindi-English mix à¤®à¥‡à¤‚ viewer à¤•à¥‹ action à¤²à¥‡à¤¨à¥‡ à¤¬à¥‹à¤²à¥‹: â€œ{d['cta']}â€

    â€”â€” STYLE & DELIVERY RULES â€”â€”
    â€¢ Short sentences (max 15 words); à¤¹à¤° 3-4 sentences à¤¬à¤¾à¤¦ à¤à¤• shorter punch-line.  
    â€¢ Viewer à¤•à¥‹ direct address à¤•à¤°à¥‹ (â€œà¤¸à¥‹à¤šà¤¿à¤â€, â€œimagine à¤•à¥€à¤œà¤¿à¤â€, â€œà¤†à¤ªà¤•à¥‡ à¤²à¤¿à¤â€).  
    â€¢ Hindi conversational, à¤ªà¤° common English words naturally à¤°à¤¹à¤¨à¥‡ à¤¦à¥‹ (â€œgrowth mindsetâ€, â€œAIâ€, â€œAtomic Habitsâ€).  
    â€¢ Active voice, vivid verbs à¤”à¤° emotion-triggering words use à¤•à¤°à¥‹.  
    â€¢ à¤•à¤¿à¤¸à¥€ à¤­à¥€ type à¤•à¤¾ fluff, clichÃ©s à¤¯à¤¾ uncertain fact à¤¬à¤¿à¤²à¥à¤•à¥à¤² à¤¨à¤¹à¥€à¤‚.  
    â€¢ Pause, tone variation à¤”à¤° question-driven rhythm à¤°à¤–à¥‡à¤‚ à¤¤à¤¾à¤•à¤¿ script naturally human à¤²à¤—à¥‡.

    Extra Notes: {d['notes'] or "None"}

    ğŸš« Return à¤¸à¤¿à¤°à¥à¤« final clean narrationâ€”plain text, à¤¬à¤¿à¤¨à¤¾ bullets, à¤¬à¤¿à¤¨à¤¾ labels, à¤¬à¤¿à¤¨à¤¾ quotes.
    """).strip()



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Script generation â”€
def generate_script(prompt, env, folder):
    client = OpenAI(api_key=env["OPENAI_API_KEY"])
    resp = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role":"system","content":"You are a gifted Hindi storyteller like Syllabus with Rohit."},
            {"role":"user","content":prompt}
        ],
        max_tokens=600,
        temperature=0.55,
        user="backtozero_youtube"
    )
    text = resp.choices[0].message.content.strip()
    save_text_to_file(text, folder/"script.txt")
    return text

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Chunked TTS + stitch audio â”€
def text_to_mp3(script, env, folder):
    voice_id = HINDI_VOICE_ID
    parts = [script[i:i+MAX_TTS_CHARS] for i in range(0, len(script), MAX_TTS_CHARS)]
    files = []
    for idx, part in enumerate(parts,1):
        r = requests.post(
            f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}",
            headers={"xi-api-key":env["ELEVENLABS_API_KEY"]}, json={"text":part, "voice_settings":{"stability":0.5,"similarity_boost":0.7}}
        )
        if r.status_code!=200:
            raise RuntimeError("TTS failed: "+r.text)
        p = folder/f"voice{idx}.mp3"
        p.write_bytes(r.content); files.append(p)
    if len(files)==1:
        out = folder/"output.mp3"; files[0].rename(out); return out
    # concat
    txt = folder/"concat.txt"
    txt.write_text("".join(f"file '{f.name}'\n" for f in files))
    out = folder/"output.mp3"
    subprocess.run([FFMPEG_CMD,"-y","-f","concat","-safe","0","-i",txt,"-c","copy",out], check=True)
    for f in files: f.unlink()
    txt.unlink()
    return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Thumbnail with smart logic â”€

def make_thumbnail(text, out_folder):
    width, height = 1280, 720
    bg_color = (20, 20, 20)
    text_color = (255, 153, 0)
    img = Image.new('RGB', (width, height), color=bg_color)
    draw = ImageDraw.Draw(img)
    try:
        font = ImageFont.truetype('/Library/Fonts/Arial.ttf', 80)
    except:
        font = ImageFont.load_default()
    bbox = draw.textbbox((0, 0), text, font=font)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]
    x = (width - text_width) / 2
    y = (height - text_height) / 2
    draw.text((x, y), text, font=font, fill=text_color)
    out_path = out_folder / "thumbnail.jpg"
    img.save(out_path)
    print(f"Thumbnail saved: {out_path}")
    return out_path


def smart_thumbnail(d, env, folder):
    # ... any advanced AI/logic you want ...
    # fallback:
    return make_thumbnail(d["thumb_txt"], folder)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ video creation â”€
def make_video(thumbnail, audio, folder):
    out = folder/"final_video.mp4"
    cmd = [FFMPEG_CMD,"-y","-loop","1","-i",thumbnail,"-i",audio,
           "-c:v","libx264","-c:a","aac","-b:a","192k","-shortest",
           "-movflags","+faststart","-vf","scale=1280:720","-pix_fmt","yuv420p",out]
    subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ YouTube upload â”€
def yt_upload(video, thumb, d):
    if not Path("token.pickle").exists():
        raise RuntimeError("token.pickle missing. Run once manually for OAuth.")
    creds = pickle.load(open("token.pickle","rb"))
    yt = build("youtube","v3",credentials=creds)
    # video
    desc = f"{d['topic']} à¤•à¤¾ à¤¸à¤¾à¤°à¤¾à¤‚à¤¶\n\nà¤®à¥à¤–à¥à¤¯ à¤¬à¤¿à¤‚à¤¦à¥:\n- "+ "\n- ".join(textwrap.wrap(d['highlights'],40))
    if d.get("attrib"):
        desc += f"\n\nImage source: {d['attrib']}"
    body = {
        "snippet": {"title":d["title"], "description":desc, "tags":[sanitize_folder_name(d['topic']),d['lang'],d['tone']], "categoryId":"22"},
        "status" : {"privacyStatus":"public","selfDeclaredMadeForKids":False}
    }
    media = MediaFileUpload(str(video), resumable=True, mimetype="video/mp4")
    rq = yt.videos().insert(part=",".join(body.keys()), body=body, media_body=media)
    resp = None
    while not resp:
        status, resp = rq.next_chunk()
        if status: logging.info("Uploading %d%%",int(status.progress()*100))
    # thumbnail
    tm = MediaFileUpload(str(thumb), mimetype="image/jpeg")
    yt.thumbnails().set(videoId=resp["id"], media_body=tm).execute()
    return f"https://youtu.be/{resp['id']}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Telegram alert â”€
def telegram_alert(env, msg):
    if env.get("TELEGRAM_BOT_TOKEN") and env.get("TELEGRAM_CHAT_ID"):
        requests.get(f"https://api.telegram.org/bot{env['TELEGRAM_BOT_TOKEN']}/sendMessage",
                     params={"chat_id":env["TELEGRAM_CHAT_ID"],"text":msg})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ process row â”€
def process(idx, row, ws, env):
    start = time.time()
    try:
        data = row_to_data(row)
        # folder
        raw = get_video_folder(VIDEOS_DIR, data["topic"], data["pub_date"])
        folder = Path(raw); folder.mkdir(parents=True, exist_ok=True)
        # prompt â†’ script
        prompt = build_prompt(data)
        save_text_to_file(prompt, folder/"final_prompt.txt")
        script = generate_script(prompt, env, folder)
        audio  = text_to_mp3(script, env, folder)
        thumb  = smart_thumbnail(data, env, folder)
        video  = make_video(thumb, audio, folder)
        link = yt_upload(video, thumb, data)
        proc_t = f"{int(time.time()-start)}s"
        # Only success if a valid link was returned
        if link and ("youtube.com/watch" in link or "youtu.be/" in link):
            batch_update(ws, idx, "âœ… Posted", link, "", proc_t)
        else:
            batch_update(ws, idx, "âŒ Error", "", "No valid YouTube link", proc_t)
    except Exception as e:
        proc_t = f"{int(time.time()-start)}s"
        batch_update(ws, idx, "âŒ Error", "", str(e), proc_t)
        logging.error("Row %s failed:\n%s", idx, traceback.format_exc())


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ main loop â”€
if __name__ == "__main__":
    env = load_env()
    ws  = sheet_ws()  # youâ€™ll need to define sheet_ws() exactly as before
    pending = list_pending(ws)
    logging.info("Found %d pending rows", len(pending))
    for idx, row in pending:
        batch_update(ws, idx, "âš™ï¸ Processing")
        process(idx, row, ws, env)
    logging.info("âœ“ All pending rows processed.")
